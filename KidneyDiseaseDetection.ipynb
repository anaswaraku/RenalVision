{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a536e8-60d0-4419-9156-d0ca72c15eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from imageio.v2 import imread\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb08afe-4204-43a0-b1da-d2a93153e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folders = [\"Cyst\", \"Stone\", \"Tumor\", \"Normal\"]\n",
    "flat_data_arr = []\n",
    "target_arr = []\n",
    "base_dir = 'Dataset'\n",
    "output_dir = 'Preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9095a764-b849-4c34-85d6-7ba7b00d9444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Path: Dataset\\Cyst\n",
      "Folder Path: Dataset\\Stone\n",
      "Folder Path: Dataset\\Tumor\n",
      "Folder Path: Dataset\\Normal\n",
      "Preprocess Completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clahe(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_image = clahe.apply(gray_image)\n",
    "    return clahe_image\n",
    "\n",
    "def gaussian_blur(image):\n",
    "    #image = cv2.imread(image_path)\n",
    "    kernel_size = (5, 5)\n",
    "    sigma = 0\n",
    "    filtered_image = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "    return filtered_image\n",
    "\n",
    "def find_contour(image):\n",
    "# Preprocessing\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, binary_image = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Contour detection\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on area or other criteria if necessary\n",
    "    # For example, you can iterate through contours and filter based on contour area:\n",
    "    # filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "\n",
    "    # Draw contours on original image\n",
    "    contour_image = image.copy()\n",
    "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "    contour_image = cv2.drawContours(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR), contours, -1, (0, 255, 0), 2)\n",
    "    return contour_image\n",
    "\n",
    "\n",
    "\n",
    "def watershed_segmentation(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert image to grayscale\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Marker labeling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Mark the unknown region with zero\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    # Apply watershed algorithm\n",
    "    markers = cv2.watershed(image, markers)\n",
    "\n",
    "    # Overlay segmentation result on original image\n",
    "    image[markers == -1] = [255, 0, 0]  # Mark watershed boundaries\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "for folder in data_folders:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    print(\"Folder Path:\", folder_path)\n",
    "    output_folder = os.path.join(output_dir, folder)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            # Preprocess image\n",
    "            preprocessed_image = clahe(image_path)\n",
    "            preprocessed_image = gaussian_blur(preprocessed_image)\n",
    "            preprocessed_image = find_contour(preprocessed_image)\n",
    "            preprocessed_image = watershed_segmentation(preprocessed_image )\n",
    "\n",
    "            # Save preprocessed image\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            cv2.imwrite(output_path, preprocessed_image)\n",
    "print('Preprocess Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490832bb-80fd-4deb-9735-f0754f2e27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the paths for your data\n",
    "data_dir = 'Preprocessed'\n",
    "train_dir = 'TRAIN'\n",
    "test_dir = 'TEST'\n",
    "val_dir = 'VAL'\n",
    "\n",
    "# Define your categories or classes\n",
    "categories = [\"Cyst\", \"Stone\", \"Tumor\", \"Normal\"]\n",
    "\n",
    "# Create train, test, and validation directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Split the data into train, test, and validation sets\n",
    "for category in categories:\n",
    "    category_dir = os.path.join(data_dir, category)\n",
    "    files = os.listdir(category_dir)\n",
    "    train_files, test_val_files = train_test_split(files, test_size=0.3, random_state=42)\n",
    "    test_files, val_files = train_test_split(test_val_files, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Move files to appropriate directories\n",
    "    for file in train_files:\n",
    "        src = os.path.join(category_dir, file)\n",
    "        dst = os.path.join(train_dir, category)\n",
    "        os.makedirs(dst, exist_ok=True)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    for file in test_files:\n",
    "        src = os.path.join(category_dir, file)\n",
    "        dst = os.path.join(test_dir, category)\n",
    "        os.makedirs(dst, exist_ok=True)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    for file in val_files:\n",
    "        src = os.path.join(category_dir, file)\n",
    "        dst = os.path.join(val_dir, category)\n",
    "        os.makedirs(dst, exist_ok=True)\n",
    "        shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "920cbc01-5aeb-4c89-bf7f-fd1ce0902026",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moffline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_notebook_mode, iplot\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tools\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import tools\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "init_notebook_mode(connected=True)\n",
    "RANDOM_SEED = 123"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
